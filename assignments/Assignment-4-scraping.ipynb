{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Scraping eBay Data Using Selenium\n",
    "\n",
    "This assignment will guide you through the steps required to scrape product data from [eBay](https://www.ebay.com/) using Selenium. Your goal is to collect data about products based on a specific search query and store the data in a CSV file for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Below is a step-by-step outline of the scraping process. Follow these steps and implement the required code to complete the assignment. Comment your code wherever necessary to explain your thought process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Set Up Selenium**\n",
    "1. Import the necessary modules from Selenium (e.g., `webdriver`, `By`, `Keys`, etc.).\n",
    "2. Set up the Chrome WebDriver to control the browser. Ensure you have downloaded the ChromeDriver executable and placed it in the correct directory.\n",
    "3. Navigate to the eBay homepage using the WebDriver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By  \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "service = Service(executable_path=\"chromedriver.exe\")\n",
    "driver=webdriver.Chrome(service=service)\n",
    "driver.get(\"https://www.google.com/\")\n",
    "search_bar=driver.find_element(By.CLASS_NAME,\"gLFyf\")\n",
    "search_bar.send_keys(\"ebay\"+Keys.ENTER)\n",
    "time.sleep(3)\n",
    "link=driver.find_element(By.PARTIAL_LINK_TEXT,\"eBay: Electronics, Cars, Fashion, Collectibles & More\")\n",
    "link.click()\n",
    "time.sleep(3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Perform a Search**\n",
    "1. Identify the search bar element on the eBay homepage using an appropriate locator (e.g., `id`, `name`, `XPath`).\n",
    "2. Send a specific search query (e.g., \"laptops\") to the search bar and simulate pressing the Enter key.\n",
    "3. Wait for the search results page to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By  \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "service = Service(executable_path=\"chromedriver.exe\")\n",
    "driver=webdriver.Chrome(service=service)\n",
    "driver.get(\"https://www.google.com/\")\n",
    "search_bar=driver.find_element(By.CLASS_NAME,\"gLFyf\")\n",
    "search_bar.send_keys(\"ebay\"+Keys.ENTER)\n",
    "time.sleep(3)\n",
    "link=driver.find_element(By.PARTIAL_LINK_TEXT,\"eBay: Electronics, Cars, Fashion, Collectibles & More\")\n",
    "link.click()\n",
    "time.sleep(3)\n",
    "search_bar=driver.find_element(By.XPATH,\"//input[@id='gh-ac']\")\n",
    "time.sleep(3)\n",
    "search_bar.send_keys(\"laptops\"+Keys.ENTER)\n",
    "time.sleep(3)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3: Extract Product Data**\n",
    "1. Use `find_elements` to locate product titles, prices, and other relevant data on the search results page. For example:\n",
    "   - Product title: Locate elements displaying the product names.\n",
    "   - Price: Locate elements showing product prices.\n",
    "   - (Optional) Link: Extract the URL for each product.\n",
    "2. Loop through the extracted elements and store the data in a structured format (e.g., a Python list of dictionaries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By  \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "service = Service(executable_path=\"chromedriver.exe\")\n",
    "driver=webdriver.Chrome(service=service)\n",
    "driver.get(\"https://www.google.com/\")\n",
    "search_bar=driver.find_element(By.CLASS_NAME,\"gLFyf\")\n",
    "search_bar.send_keys(\"ebay\"+Keys.ENTER)\n",
    "time.sleep(3)\n",
    "link=driver.find_element(By.PARTIAL_LINK_TEXT,\"eBay: Electronics, Cars, Fashion, Collectibles & More\")\n",
    "link.click()\n",
    "time.sleep(3)\n",
    "search_bar=driver.find_element(By.XPATH,\"//input[@id='gh-ac']\")\n",
    "time.sleep(3)\n",
    "search_bar.send_keys(\"laptops\"+Keys.ENTER)\n",
    "time.sleep(3)\n",
    "names=driver.find_elements(By.XPATH,\"//span[@role='heading']\")\n",
    "prices=driver.find_elements(By.XPATH,\"//span[@class='s-item__price']\")\n",
    "links=driver.find_elements(By.XPATH,\"//a[@class='s-item__link']\")\n",
    "items=[]\n",
    "i=1\n",
    "for name,price,link in zip(names,prices,links):\n",
    "    try :\n",
    "        item_link=link.get_attribute(\"href\")\n",
    "        print(f\"{i}-name :\"+ name.text)\n",
    "        print(f\"{i}-price :\"+ price.text)\n",
    "        print(f\"{i}-link :\"+item_link)\n",
    "        i+=1\n",
    "        print(\"-\"*40)\n",
    "        items.append([name.text,price.text,item_link])\n",
    "       \n",
    "    except Exception as e:\n",
    "        print(\"error\"+e)  \n",
    "driver.quit()        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4: Handle Pagination**\n",
    "1. Check for the presence of a \"Next\" button to navigate to the next page of results.\n",
    "2. Implement a loop to scrape multiple pages of search results. Break the loop when no more pages are available or after a set number of pages (e.g., 5 pages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By  \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "service = Service(executable_path=\"chromedriver.exe\")\n",
    "driver=webdriver.Chrome(service=service)\n",
    "driver.get(\"https://www.google.com/\")\n",
    "search_bar=driver.find_element(By.CLASS_NAME,\"gLFyf\")\n",
    "search_bar.send_keys(\"ebay\"+Keys.ENTER)\n",
    "time.sleep(3)\n",
    "link=driver.find_element(By.PARTIAL_LINK_TEXT,\"eBay: Electronics, Cars, Fashion, Collectibles & More\")\n",
    "link.click()\n",
    "time.sleep(3)\n",
    "search_bar=driver.find_element(By.XPATH,\"//input[@id='gh-ac']\")\n",
    "time.sleep(3)\n",
    "search_bar.send_keys(\"laptops\"+Keys.ENTER)\n",
    "time.sleep(5)\n",
    "names=driver.find_elements(By.XPATH,\"//span[@role='heading']\")\n",
    "prices=driver.find_elements(By.XPATH,\"//span[@class='s-item__price']\")\n",
    "links=driver.find_elements(By.XPATH,\"//a[@class='s-item__link']\")\n",
    "items=[]\n",
    "i=1\n",
    "no_pages=1\n",
    "while no_pages<=5:\n",
    "   for name,price,link in zip(names,prices,links):\n",
    "     try :\n",
    "        item_link=link.get_attribute(\"href\")\n",
    "        print(f\"{i}-name :\"+ name.text)\n",
    "        print(f\"{i}-price :\"+ price.text)\n",
    "        print(f\"{i}-link :\"+item_link)\n",
    "        i+=1\n",
    "        print(\"-\"*40)\n",
    "        items.append([name.text,price.text,item_link])\n",
    "       \n",
    "     except Exception as e:\n",
    "        print(\"error\"+e)    \n",
    "   try :\n",
    "      \n",
    "      next_link=driver.find_element(By.XPATH,\"//a[@type='next']\")\n",
    "      next_link.click\n",
    "      time.sleep(3)\n",
    "      \n",
    "   except Exception as e:\n",
    "      print(\"no more pages\"+e)  \n",
    "      break\n",
    "   no_pages+=1 \n",
    "driver.quit      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 5: Save Data to CSV**\n",
    "1. Use the `pandas` library to convert the scraped data into a DataFrame.\n",
    "2. Save the DataFrame to a CSV file with appropriate column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "laptops=pd.DataFrame(items,columns=[\"names\",\"prices\",\"links\"])\n",
    "laptops.to_csv(\"ebay 'laptops'.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 6: Close the Browser**\n",
    "1. Once the scraping is complete, ensure the WebDriver is closed to release system resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deliverables**\n",
    "- Submit the Python script you implemented on your github, following the above steps.\n",
    "- Ensure that your script:\n",
    "  - Extracts data for at least 50 products.\n",
    "  - Includes product titles, prices, and links (if applicable).\n",
    "  - Saves the data to a CSV file named `ebay_products.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Bonus Challenge**\n",
    "1. Add functionality to scrape product ratings and the number of reviews (if available).\n",
    "2. Include error handling to skip elements that might be missing data or inaccessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By  \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "service = Service(executable_path=\"chromedriver.exe\")\n",
    "driver=webdriver.Chrome(service=service)\n",
    "driver.get(\"https://www.google.com/\")\n",
    "search_bar=driver.find_element(By.CLASS_NAME,\"gLFyf\")\n",
    "search_bar.send_keys(\"ebay\"+Keys.ENTER)\n",
    "time.sleep(3)\n",
    "link=driver.find_element(By.PARTIAL_LINK_TEXT,\"eBay: Electronics, Cars, Fashion, Collectibles & More\")\n",
    "link.click()\n",
    "time.sleep(3)\n",
    "search_bar=driver.find_element(By.XPATH,\"//input[@id='gh-ac']\")\n",
    "time.sleep(3)\n",
    "search_bar.send_keys(\"laptops\"+Keys.ENTER)\n",
    "time.sleep(5)\n",
    "names=driver.find_elements(By.XPATH,\"//span[@role='heading']\")\n",
    "prices=driver.find_elements(By.XPATH,\"//span[@class='s-item__price']\")\n",
    "links=driver.find_elements(By.XPATH,\"//a[@class='s-item__link']\")\n",
    "ratings=driver.find_elements(By.XPATH,\"//span[@class='s-item__seller-info-text']\")\n",
    "items=[]\n",
    "i=1\n",
    "no_pages=0  \n",
    "while no_pages<=5:\n",
    "   for name,price,link,rating in zip(names,prices,links,ratings):\n",
    "     try :\n",
    "        item_link=link.get_attribute(\"href\")\n",
    "        print(f\"{i}-name :\"+ name.text)\n",
    "        print(f\"{i}-price :\"+ price.text)\n",
    "        print(f\"{i}-link :\"+item_link)\n",
    "        print(f\"{i}-seller--number_of_reviews--percentage :\"+rating.text)\n",
    "        i+=1\n",
    "        print(\"-\"*40)\n",
    "        items.append([name.text,price.text,item_link,rating.text])\n",
    "       \n",
    "     except Exception as e:\n",
    "        print(\"error\"+e)    \n",
    "   try :\n",
    "      \n",
    "      next_link=driver.find_element(By.XPATH,\"//a[@type='next']\")\n",
    "      next_link.click\n",
    "      time.sleep(3)\n",
    "      \n",
    "   except Exception as e:\n",
    "      print(\"no more pages\"+e)  \n",
    "      break\n",
    "   no_pages+=1 \n",
    "driver.quit      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Good luck!** 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
