{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c47d3205",
   "metadata": {},
   "source": [
    "## Web Scraping Demo\n",
    "This is a simple demonstration of web scraping using Python. The code uses libraries such as `requests` and `BeautifulSoup` to extract job data from websites like Wuzzuf and Bayt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1effd65f",
   "metadata": {},
   "source": [
    "### Step 1: Install Required Libraries\n",
    "Install the `lxml` library for HTML parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97ce27d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in e:\\tools\\envs\\depi_env\\lib\\site-packages (5.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3c975f",
   "metadata": {},
   "source": [
    "### Step 2: Import Required Libraries\n",
    "Import the necessary libraries for making HTTP requests and parsing HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "453dad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d988e9",
   "metadata": {},
   "source": [
    "### Step 3: Scrape Wuzzuf for Job Data\n",
    "Define the target URL and fetch the page content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfd6b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL for Wuzzuf search page\n",
    "u = \"https://wuzzuf.net/search/jobs?a=spbg&q=machine%20learning\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "page = requests.get(u)\n",
    "\n",
    "# Parse the page content using BeautifulSoup\n",
    "soup= BeautifulSoup(page.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4907519d",
   "metadata": {},
   "source": [
    "#### Step 3.1: Extract Job Titles\n",
    "Use BeautifulSoup to find and print all job titles on the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c679d1f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Find all job titles on the page\u001b[39;00m\n\u001b[0;32m      4\u001b[0m title\u001b[38;5;241m=\u001b[39msoup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh2\u001b[39m\u001b[38;5;124m'\u001b[39m,class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcss-m604qf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m)\n",
      "File \u001b[1;32me:\\tools\\envs\\depi_env\\lib\\site-packages\\bs4\\element.py:2433\u001b[0m, in \u001b[0;36mResultSet.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   2432\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   2434\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResultSet object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key\n\u001b[0;32m   2435\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "# Find all job titles on the page\n",
    "\n",
    "\n",
    "title=soup.find_all('h2',class_=\"css-m604qf\")\n",
    "                \n",
    "                \n",
    "print(title.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6996fb4",
   "metadata": {},
   "source": [
    "#### Step 3.2: Extract Job Locations\n",
    "Extract and print the locations of the jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98b37742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cairo, Egypt \n",
      "Alexandria, Egypt \n",
      "Downtown, Cairo, Egypt \n",
      "Manchester, United Kingdom \n",
      "Larnaca, Cyprus \n",
      "Sheikh Zayed, Giza, Egypt \n",
      "Riyadh, Saudi Arabia \n",
      "Damietta, Egypt \n",
      "Cairo, Egypt \n",
      "Riyadh, Saudi Arabia \n",
      "Cairo, Egypt \n",
      "10th of Ramadan City, Sharqia, Egypt \n",
      "New Cairo, Cairo, Egypt \n",
      "Hadayek Alahram, Giza, Egypt \n",
      "Cairo, Egypt \n"
     ]
    }
   ],
   "source": [
    "# Find all job locations\n",
    "location = soup.find_all('span',class_=\"css-5wys0k\")\n",
    "for i in location:\n",
    "    print(i.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99a0613",
   "metadata": {},
   "source": [
    "#### Step 3.3: Extract Company Names\n",
    "Extract and print the company names associated with the jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e03db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all company names\n",
    "\n",
    "com=soup.find_all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b522d4",
   "metadata": {},
   "source": [
    "#### Step 3.4: Extract Job Post Dates\n",
    "Extract and print when the jobs were posted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "858e39c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 month ago\n",
      "12 days ago\n",
      "3 hours ago\n",
      "2 months ago\n",
      "1 month ago\n",
      "15 days ago\n",
      "1 month ago\n",
      "5 days ago\n",
      "28 days ago\n",
      "1 day ago\n",
      "6 days ago\n",
      "13 days ago\n",
      "29 days ago\n",
      "6 days ago\n",
      "13 days ago\n"
     ]
    }
   ],
   "source": [
    "# Find all job posting dates\n",
    "\n",
    "date=soup.find_all('div',class_=[\"css-do6t5g\"  ,\"css-4c4ojb\"] )\n",
    "for i in date:\n",
    "    print(i.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11b3733",
   "metadata": {},
   "source": [
    "#### Step 3.5: Extract Job Types\n",
    "Extract and print the types of jobs (e.g., Full-time, Part-time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1f44af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all job types\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb73568e",
   "metadata": {},
   "source": [
    "#### Step 3.6: Extract Job URLs\n",
    "Extract and print the URLs for individual job postings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "86836d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://wuzzuf.net/jobs/p/ow9y8zcxQbne-Machine-Learning-Manager-kcsc-Cairo-Egypt\n",
      "https://wuzzuf.net/jobs/p/jjEycNgftu1U-Robotics-and-Programming-Engineer-Smart-Technology-Alexandria-Egypt\n",
      "https://wuzzuf.net/jobs/p/PfXPkSfnCCNs-Sales-Specialist-Gila-Electric-Cairo-Egypt\n",
      "https://wuzzuf.net/jobs/p/3k4DYwP9VAza-Senior-Backend-Developer-in-NodeExpress-Give-Brite-Manchester-United-Kingdom\n",
      "https://wuzzuf.net/jobs/p/eRVXqix8zgJQ-Machinist-Mechanical-Engineer-kpec-international-Larnaca-Cyprus\n",
      "https://wuzzuf.net/jobs/p/1kRUuVPxsf8W-AI-Technical-Team-Lead-Computer-Vision-Focus-NLP-Lumin-Giza-Egypt\n",
      "https://wuzzuf.net/jobs/p/Ej8oiMp2sfqj-Online-Coding-Instructor-Riyadh-Saudi-Arabia\n",
      "https://wuzzuf.net/jobs/p/iitM79Aq3BJp-Senior-ML-JD-ysolution-Damietta-Egypt\n",
      "https://wuzzuf.net/jobs/p/YqALuLpVSgcA-Senior-AI-Engineer-RMG-Cairo-Egypt\n",
      "https://wuzzuf.net/jobs/p/lewDJYtw0FhS-Senior-Full-Stack-Embedded-Engineering-Qudra-Tech-Riyadh-Saudi-Arabia\n",
      "https://wuzzuf.net/jobs/p/YhxFt5TgYjpF-Senior-Full-Stack-Developer-MERN-or-Laravel-Stack-Si-Vision-Cairo-Egypt\n",
      "https://wuzzuf.net/jobs/p/41ZtIDJmT23i-Process-Electronics-Engineer-VIVO-Sharqia-Egypt\n",
      "https://wuzzuf.net/jobs/p/ThCwX7BRCFwL-AWS-Cloud-Administrator-Citylogix-ME-Cairo-Egypt\n",
      "https://wuzzuf.net/jobs/p/sRnWBoAEpms2-Technical-sales-and-marketing-manager-Etkaan-Giza-Egypt\n",
      "https://wuzzuf.net/jobs/p/jQJ76XdAyBjB-E-Commerce-Assistant---Remote-Cairo-Egypt\n"
     ]
    }
   ],
   "source": [
    "# Extract job URLs\n",
    "\n",
    "urls=soup.find_all('h2',class_=\"css-m604qf\")\n",
    "\n",
    "for i in urls:\n",
    "    a_tag=i.find('a')\n",
    "    print(a_tag.get('href'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e3d2b7",
   "metadata": {},
   "source": [
    "#### Step 3.7: Fetch Individual Job Details\n",
    "Fetch and print the titles of individual jobs from their URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfede130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example URL for testing\n",
    "url = \"https://wuzzuf.net/jobs/p/5NFxSMKMH5K0-SeniorMid-Senior-Deep-Learning-Engineer-Cairo-Egypt?o=1&l=sp&t=sj&a=machine%20learning|search-v3|spbg\"\n",
    "\n",
    "# Send a GET request and parse the content\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b251a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba421ca",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee778eef",
   "metadata": {},
   "source": [
    "### Step 4: Scrape Bayt for Job Data\n",
    "Switch to a different platform and extract job data from Bayt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1f0654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Bayt URL for data science jobs\n",
    "url = \"https://www.bayt.com/en/egypt/jobs/data-science-jobs/\"\n",
    "\n",
    "# Send a GET request with a user-agent header to mimic a browser\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211f3707",
   "metadata": {},
   "source": [
    "#### Step 4.1: Extract Job Titles on Bayt\n",
    "Extract and print job titles from Bayt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2dc97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all job titles on the page\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367a3306",
   "metadata": {},
   "source": [
    "#### Step 4.2: Extract Job URLs on Bayt\n",
    "Extract and print the URLs for job postings on Bayt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a9d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract job URLs on Bayt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320e9ff1",
   "metadata": {},
   "source": [
    "### Quizzes\n",
    "Try to find additional information from the scraped pages using the following tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f0c1c2",
   "metadata": {},
   "source": [
    "#### Quiz 1: Find the Locations of Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b407662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the location\n",
    "location = soup.find_all(\"....\", class_ =\"...\")\n",
    "for l in location:\n",
    "    print(l.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905d9eec",
   "metadata": {},
   "source": [
    "#### Quiz 2: Find the Company Names of Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c960a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the company\n",
    "company = soup.find_all(\"...\", class_ =\"....\")\n",
    "for c in company:\n",
    "    print(c.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7693e3c4",
   "metadata": {},
   "source": [
    "#### Quiz 3: Extract Job Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f99c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job descreption\n",
    "desc = soup.find_all(\"....\", class_ =\"...\")\n",
    "for d in desc:\n",
    "    print(d.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
